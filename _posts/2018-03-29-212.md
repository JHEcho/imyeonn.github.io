---
title: "알렉사가 대화만으로 만드는 경험"
layout: post
date: 2018-03-29 14:50
image: /assets/images/post/002/212_00title.png
headerImage: true
category: E-Commerce
tag:
- 대화형인터페이스
- 음성비서
- 개인화추천
- 인공지능
blog: true
author: Hyeyeon
description: 알렉사가 대화로 만드는 경험
---

### Summary:

대화 설계의 키워드 = **맥락과 의도**

---

## 알렉사와의 신기한 경험

*"목소리만으로 아프리카 탐험을 떠났다. 코끼리를 보고 언덕을 올랐다. 내 선택에 따라 매번 다른 시나리오가 펼쳐졌고 사운드 효과는 몰입감을 더했다. 알렉사와 사파리에 갈 수 있을 것이라곤 상상도 하지 못했다."*

[My African Safari](https://www.amazon.com/Yancey-Skills-My-African-Safari/dp/B07BJLSV9M)라는 알렉사 스킬의 이용 후기다. My African Safari는 한 개인이 제작하여 아마존에 등록한 크루거 국립 공원에서의 어드벤쳐 게임이다. 사자를 몰래 쫓아가거나 덤불을 헤치고 암벽그림을 그리는 등 예기치 못한 모험과 탐험을 떠날 수 있다. 2개 지역, 8개 이야기, 26개의 다른 결말로 구성되어 있다.

---

## 알렉사 스킬스(Alexa Skills)

![알렉사의 다양한 스킬들(thequill.in)](/assets/images/post/002/212_01.jpg)

아마존은 알렉사 스킬스 생태계를 구축하고 있다. 회사나 개인의 구분 없이 누구나 알렉사에 원하는 명령이나 기능을 추가할 수 있다. 오픈 API 효과로 알렉사의 파급력이 향상되는 건 물론이다. 최근에는 코딩없이 알렉사 스킬을 만들 수 있는 [스토리라인](https://getstoryline.com/)이라는 툴도 등장했다.

현재 아마존에 등록된 알렉사 스킬은 30,000개가 넘는다([기사](https://www.voicebot.ai/2018/03/22/amazon-alexa-skill-count-surpasses-30000-u-s/)). PC에서 모바일로 넘어오던 시절 앱스토어에 등록된 앱이 500여개 밖에 되지 않았다고 하니 삼만 개가 결코 적은 숫자가 아니다. 뉴스 브리핑나 게임, 스토리텔링, 음악감상 등 음성경험의 카테고리도 다양해지고 있다.

스마트폰은 애플이 만들었지만 앱스토어에 등록된 수많은 앱은 애플 외부 개발자들이 만들어 모바일앱 생태계를 확장했던 것과 유사하다. 알렉사의 유명한 기능 대부분은 아마존이 직접 만든 것이 아니라 외부에서 개발하고 아마존 스킬에 등록한 추가 기능이다.

<iframe width="560" height="315" src="https://www.youtube.com/embed/yXUEzD9Cqi8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

![데낄라 제조업체 패트론도 자사 브랜드로 개인화된 경험을 제공하기 위한 알렉사 스킬을 등록했다.]()

---

## '대화'

이 스킬들, 다시 말해 음성 플랫폼 앱들의 공통점은 '대화'다. 터치 인터페이스 기반 앱을 쓸 때 사람들은 앱의 이름을 부르고 말을 걸지 않았다. 그러나 음성 인터페이스에선 에코를 의인화한다.

[코넬대학교의 연구](https://dl.acm.org/citation.cfm?id=3053246)는 사람들이 스마트 스피커와 그 안에 탑재된 AI를 동일시하는 경향이 있다고 말했다. 알렉사를 정보 제공 장치나 쇼핑, 일정 관리에 도움을 주는 존재를 넘어서서 친밀한 관계를 쌓아가는 객체로 인식했고 일부 강한 사회성을 갖는 사용자는 알렉사를 자신의 베스트프랜드(BFF, Best Friends Forever)로 대하기도 했다.

![사용자는 알렉사에게 다양한 역할을 기대한다.(코넬대학교)](/assets/images/post/002/212_02.png)

알렉사는 기계다. 알렉사라는 사람 이름이 붙었지만 사실 알렉사는 아마존의 스마트 스피커인 에코 안에 들어있는 시스템일 뿐이다. 우리는 이 기계를 도우미, 어시스턴트로 생각하고 이름을 부르며 친밀감을 갖기 시작했다. 대화라는 요소는 문장으로 소통하고 문장에는 감정이 들어있기 때문에 터치 인터페이스에서 낱말 단위로 기능을 요청하고 받아들였던 것과는 사뭇 다르다.

대화형 인터페이스가 말을 잘 알아듣지 못하고 음악 재생 도구밖에 되지 않아 제한적이다는 비판이 무색하게 [스마트 스피커와의 대화가 친구에게 말하는 것과 비슷한 느낌이 든다](https://www.thinkwithgoogle.com/consumer-insights/voice-assistance-consumer-experience/)는 응답 비중이 점차 증가했다. 사용자의 의사결정을 돕는 스킬이 증가하고 각종 교육, 정보 콘텐츠나 오디오 기반 게임도 점차 확대되고 있다. 우리는 음성 플랫폼과 더 많은 대화를 하고 돈독한 사이가 될 것이다.

![think with Google](/assets/images/post/002/212_03.png)

마크 주커버그는 [Building Jarvis](https://www.facebook.com/notes/mark-zuckerberg/building-jarvis/10154361492931634/)에서
"시스템과 음성으로 대화하기 시작하면 텍스트나 그래픽으로 하는 것보다 더 깊은 감정을 느끼게 된다"(On a psychologic level, once you can speak to a system, you attribute more emotional depth to it than a computer you might interact with using text or a graphic interface.)고 말했다.

---

## 대화를 설계한다는 것

대화를 설계한다는 것은 흐름, 단계를 그리는 것과 같다. 눈에 보이는 것이 없기에 화면을 스케치하지 않고 플로우를 그리며 맥락과 의도에 더 집중하게 된다. 앞서 언급했던 알렉사 스킬 제작 툴인 스토리라인으로 대화형 인터페이스를 설계할 때도 그렇다.

스토리라인은 드래그 앤 드롭으로 플로우 차트를 그리면서 알렉사 스킬을 만들도록 유도한다. My African Safari의 최종산출물 역시 UI 컴포넌트가 하나도 없는 플로우 차트였다. [My African Safari 프리뷰](https://getstoryline.com/shared/projects/f6f63eb7f69d1dc8795938728675942c20c46b0e)에서 전체 플로우를 확인하고 직접 음성으로 테스트해볼 수도 있다.

![My African Safari의 흐름도 일부](/assets/images/post/002/212_04.png)

지금은 대화로 사용자를 이해하고 친구처럼 니즈를 예측하는 단계로 진화시키기 위한 초기 단계에 있다. 터치 인터페이스는 내 상태를 모른다. 내가 기쁘거나 슬픈지, 배가 고픈지, 심심한지 바쁜지, 운동이 필요한지는 물론 지금 어디에 있는지조차 모르기도 한다. 그러나 나의 친구와 가족은 내 말 몇 마디로 나를 파악한다. 내 상태를 굳이 다 설명하지 않아도 맥락을 바로 이해하고 적절한 액션을 취한다.

음성 인터페이스를 설계한다는 건 내 필요에 따라 기계가 날 이해하고 반응하도록 만드는 것과 같다. 기계가 감정이 담긴 소통방식을 이해하는 게 우선이고, 더 잘 보이는 화면, 훌륭한 음질, 눈을 사로잡는 효과는 나중의 일이다.

우리부터도 사람과 얘기할 때 처음에는 생김새나 행동을 의식하지만 곧 대화와 소통으로 관계가 깊어지지 않나. 사용자의 말, 전후 맥락을 잘 이해하고 신뢰감과 공감을 불러일으키는 프로세스 설계가 음성경험의 승패를 가른다.

<iframe width="560" height="315" src="https://www.youtube.com/embed/PCNZK47qCMw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

![할머니와 구글홈과의 대화]()

때로 기능이나 화면을 안 써도 될 때는 쓰지 않고도 태스크를 달성할 수 있게 만들고, 일련의 대화를 거침으로써 막연함을 명확함으로 치환하는 것이 내가 생각하는 UX의 지향점이다. 다수 시나리오를 염두하여 단계적으로 사용자의 의도에 반응하고 지속적인 신뢰감과 충성도를 확보해나가는 것이다.

이 부분이 음성 인터페이스가 중요한 이유가 되기도 하다. 화면이 제한적이기에 니즈가 발생하는 본질에 더 집중할 수 있다. 그 궁극적인 맥락과 의도를 이해하여 사용자의 장애물에 제대로 공감할 수 있다. 전달하고 싶은 콘텐츠보다 사용자에게 진정 가치 있는 콘텐츠가 뭔지, 실제 문제 해결에 도움이 되는지 등 고민도 깊어질 것이다.

마케팅 에이전시 엡실론(Epsilon)의 톰 에드워즈는 "음성은 무한한 인터페이스"라고 단언했다. 엄청난 선택의 폭을 추려내어 명확한 길을 제시하고, 사용자가 선택한 결과를 재확인하며, 간결하게 방향을 제공하는 등 실은 무한한 검색 결과를 보여주는 것을 의미하기 때문이다.

---

## 방향

맥락과 의도를 이해한다는 것을 음성 인터페이스에만 국한된 숙명으로 한정지어서는 안 된다. 터치 인터페이스가 당면한 가장 큰 과제 중에 하나가 사용자의 의도를 이해하고 필요한 것만 제공하는 개인화된 인터페이스를 만드는 것이기 때문이다. 현 GUI 환경에선 되려 화면의 자유도가 높은 것이 단점이 되어 여러 요소를 뿌려놓고 그 중에 하나라도 사용자의 의도에 부합하는 것이 있으면 된다는 식의 서비스가 많다.

음성이든 화면이든 서비스와 사용자의 상호작용을 설계한다는 점에서 본질은 같다. 어떻게 보여지는지에 앞서 사람들의 미묘한 검색 방법의 차이를 이해하고 목표를 달성할 수 있도록 하는 것, 맥락을 반영한 개인화된 인터페이스 구축으로 신속정확하게 니즈를 충족시키는 것이 화면의 유무를 떠난 UX의 목적이다.

음성이 내 분야엔 유용하지 않을 것 같다는 이유로, 한계가 너무 많다거나 리소스 대비 효율이 떨어진다는 현재 시점의 섣부른 판단으로 음성 설계는 내 몫이 아니라고 말하는 건 잘못된 태도였다.

화면을 설계하는 것과 음성을 설계하는 것은 동떨어진 분야가 아니다. 사실 우린 항상 서비스와 대화해왔지 않나. 인간의 언어가 서비스에 닿기까지 번역기 역할을 도스창과 버튼이 대신했을 뿐이다. CLI부터 GUI, 이제 주목받는 CUI, VUI까지. 이제는 공간에 펼쳤던 UX를 시간에 펼칠 때다.

---
